---
title: "Project 2"
author: "Cecilia Smith, Sofia Zajec, TJ Gwilliam, Reese Quillian"
date: "December 8, 2022"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
require("knitr")
datadir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/In Class/Data/AirQualityUCI"
sourcedir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/Project 2"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
library(ggplot2)
library(ggfortify)
library(tseries)
library(ggpubr)
library(tidyverse)
```

# Load data and impute missing values
```{r cars}
setwd(datadir)

airquality = read.csv('AirQualityUCI.csv')

# replace -200 with NA
airquality[airquality == -200] <- NA

# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
  airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}

setwd(sourcedir)

# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]

# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam',
             ga.control=list(formula=paste(names(AQdata)[c(1:2)],'~ns(t,2)')))

# set airquality to imputed data
AQdata <- i$filled.dataset

# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
```


# Part 1: Building Univariate Time Series Models

Build a time series model of daily maximum nitrogen dioxide (NO2) concentrations using all but the last 7 days of observations

```{r}
# use dataframe dailyAQ, remove last 7 days
dailyNO2 <- head(dailyAQ$NO2.GT., -7)

dailyNO2.ts <- ts(dailyNO2)

# create time element
time.NO2<-c(1:(length(dailyNO2.ts)))
```


#### 1.1 Seasonal components

To begin, we check for seasonal components using a periodogram:

```{r}
pg.NO2 <- spec.pgram(dailyNO2.ts,spans=9,demean=T,log='no')
```

```{r}
# Find the peak, max.omega.NO2
max.omega.NO2<-pg.NO2$freq[which(pg.NO2$spec==max(pg.NO2$spec))]

# Where is the peak?
max.omega.NO2

# What is the period?
1/max.omega.NO2
```

```{r}
# What are the periods of the next biggest peaks?
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
names(sorted.spec)

# corresponding periods (omegas = frequencies, Ts = periods)
sorted.omegas <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]

# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
```


In order to determine if there is any seasonality, we created a periodogram of daily NO2 values. This yielded a maximum omega value of 0.0052, corresponding to a period of 192 days. We looked at the values for the next highest peaks because the first peak could be considered red noise. The second peak has a period of approximately 7 days, which is what we would expect for pollution data. 


```{r}
# Model seasonality
# from before: period = 7
NO2.trend.seasonal <- lm(dailyNO2.ts ~ time.NO2 + sin(2*pi*time.NO2/7)
                         + cos(2*pi*time.NO2/7))
summary(NO2.trend.seasonal)
```


We then created a model to include the trend and seasonality which determined that both the trend and 7 day seasonality are significant. We can then plot the trend/seasonal model onto the data in order to get a better visualization. 

```{r}
dailyAQ1 <- head(dailyAQ, -7)   

# Plot seasonal model
ggplot(dailyAQ1, aes(x=Group.1,y=NO2.GT.)) + geom_line() + 
  geom_line(aes(x=Group.1,y=NO2.trend.seasonal$fitted.values),color="red") +
  xlab("") + ylab("GT NO2")
```


```{r}
# Model diagnostics for NO2.trend.seasonal
autoplot(NO2.trend.seasonal, labels.id = NULL)
```

We then checked the diagnostic plots to make sure that the underlying assumptions were being met. As seen above, the residual versus fitted and residuals versus leverage could definitely be improved (the variance does not appear constant and there is slight indication of nonzero mean), however the QQ plot seems to be acceptable. 


```{r}
# check to make sure no points have cooks distance higher than 0.5
autoplot(NO2.trend.seasonal,which=4,ncol=1,label.size=3) + theme_bw()
```


Lastly, we considered Cooks distance to ensure that no influential points were present and skewing or influencing our data. As none of the data points had a cooks distance  greater than 0.5, there proved no reason to remove any of the data points.


#### 1.2 Trend

```{r}
plot(dailyNO2.ts)
```


To determine any trend within the data, we plotted the data as a whole to begin with a simple visualization. Based on the plot above, there appears to be a general increasing trend.

```{r}
NO2.trend<-lm(dailyNO2.ts ~ time.NO2)
summary(NO2.trend)
```


After the initial visualization plot, we created the trend model to determine if the trend was significant. As seen in the output above, the trend is significant with a very low P-value of <2.2e-16. 


```{r}
# Plot NO2.trend model
ggplot(dailyAQ, aes(x=Group.1,y=NO2.GT.)) + geom_line() +
  stat_smooth(method="lm",col="red") + xlab("") + ylab("GT NO2")
```

Furthermore, we can then plot the trend model on the existing data to visualize the relationship. 

```{r}
# Model diagnostics for temp.trend
autoplot(NO2.trend, labels.id = NULL)
```

These diagnostic plots reveal that there are three potential outliers. Therefore, we will check the Cook's distances below. The diagnostics of this model are very similar to our trend.seasonal model: decent meeting of assumptions in the QQ plot, but Residuals v. Fitted and Scale-Location show some issues with non-constant mean and variance.

```{r}
# check to make sure no points have cooks distance higher than 0.05
autoplot(NO2.trend,which=4,ncol=1,label.size=3) + theme_bw()
```


Again, similar to the seasonality model, none of the points have a Cook’s distance greater than 0.5 and therefore do not require removal. 


#### 1.3 Autoregressive and moving average components

Now we will check for autoregressive and moving average components.

```{r}
# using acf and pcf
# Get the residuals from the NO2.trend model above and store in e.ts.NO2:
e.ts.NO2 <- ts(NO2.trend$residuals)
    
# Plot the residuals for the temp.trend model
autoplot(e.ts.NO2)
```

```{r}
# ACF
NO2.acf <- ggAcf(e.ts.NO2)

# PACF
NO2.pacf <- ggPacf(e.ts.NO2)

# Plot acf and pacf side by side for easier examination
ggarrange(NO2.acf,NO2.pacf,nrow=2,ncol=1)
```


Based on the shapes of both plots, we assume that there are definitely autoregressive terms present. Further, we believe that we can model the NO2 emissions as an AR(1) model. This is because:

- The acf shows sinusoidal decay

- The pacf cuts off after 1 lag


```{r}
# build ar1 model
NO2.ar1 <- arma(e.ts.NO2, order=c(1,0))
summary(NO2.ar1)

# without intercept
NO2.ar1 <- arma(e.ts.NO2, order=c(1,0), include.intercept = FALSE)
summary(NO2.ar1)

# using arima
# ar(1) p=1
NO2.ar1.1 <- arima(e.ts.NO2, order=c(1,0,0), include.mean=FALSE)
summary(NO2.ar1.1)
```


We will move forward with the arima model, so that we can compare other models using the AIC() and BIC() function.

Now we will use automatic model selection to build a second model, and later compare the two to use for the rest of our analysis.


```{r}
# automatic model selection
NO2.auto <- auto.arima(e.ts.NO2)
summary(NO2.auto)

NO2.auto1 <- auto.arima(e.ts.NO2,approximation=FALSE)
summary(NO2.auto1) # smaller AIC - use this
```


#### 1.4 Model assessment

We start by comparing the AIC of the two models:

```{r}
# AIC:
AIC(NO2.ar1.1)
AIC(NO2.auto1)
```

And now BIC:

```{r}
# BIC
BIC(NO2.ar1.1)
BIC(NO2.auto1)
```

The automatic selection model has both a lower AIC and BIC, making it a better choice. We will now check other diagnostics before moving forward with the auto model.

```{r}
# diagnostics: residuals v. fit
model1 = ggplot() + geom_point(aes(x=fitted(NO2.ar1.1), y=NO2.ar1.1$residuals)) + ggtitle("AR1")
model2 = ggplot() + geom_point(aes(x=fitted(NO2.auto1), y=NO2.auto1$residuals)) + ggtitle("Auto")

ggarrange(model1, model2, ncol=2, nrow=1)
```


```{r}
# assess normality of residuals
model1 = qplot(sample=NO2.ar1.1$residuals) + stat_qq_line(color="red") + ggtitle("AR1")
model2 = qplot(sample=NO2.auto1$residuals) + stat_qq_line(color="red") + ggtitle("Auto")

ggarrange(model1, model2, ncol=2, nrow=1)
```


```{r}
ggtsdiag(NO2.ar1.1,gof.lag=20)
```

```{r}
ggtsdiag(NO2.auto1,gof.lag=20)
```


The Ljung-Box plot shows that both models are adequate up to lag 7. In terms of the residual v. fit and QQ plots, both models are very similar and meet assumptions. 

Because both models are very similar in diagnostics, we choose the automatically selected model due to the lower AIC and BIC. This is what will be used for the remainder of our analysis. 


#### 1.5 7 day forecast

Now we forecast the next 7 days of NO2 concentrations using the NO2.auto model.

```{r}
NO2.auto.forecast <- forecast(NO2.auto1, h=7)

autoplot(NO2.auto.forecast,main="Forecasts from ARIMA(1,1,1) with zero mean")
```


```{r}
anova(NO2.trend,NO2.trend.seasonal)
```

```{r}
AIC(NO2.trend)
AIC(NO2.trend.seasonal)
```

Based on the results above, and the fact that the trend and trend.seasonal model showed similar diagnostics, we will use the trend.seasonal model to make our predictions since it has a lower AIC and adding seasonality adds predictive power at the .05 level (the p-value for the anova test < 0.05)


```{r}
# Prediction performance
# Create test set from temp data set with last 7 days

# The test period in days
next.7d.time <- c((length(dailyNO2)-6):(length(dailyNO2)))

# The test data frame
next.7d <- data.frame(time.NO2 = next.7d.time, NO2 = dailyNO2[next.7d.time])

# The actual time series for the test period
next.7d.ts <- ts(next.7d$NO2)

# Prediction for the next 6 months by temp.auto:
E_Y.pred <- predict(NO2.trend.seasonal, newdata=next.7d)
e_t.pred <- forecast(NO2.auto1, h=7)
next.7d.prediction <- E_Y.pred + e_t.pred$mean
```


```{r}
# MSE:
mean((next.7d.prediction-next.7d$NO2)^2)
```

Our forecast yields a MSE of 1080. We can now plot the predicted vs. actual values to see how they compare for the last 7 days of the data:

```{r}
# Plot actual values and predicted values
plot(ts(next.7d$NO2),type='o',ylim=c(120,230))
lines(ts(next.7d.prediction),col='red',type='o')
lines(1:7, E_Y.pred + e_t.pred$lower[,2], col = "red", lty = "dashed")
lines(1:7, E_Y.pred + e_t.pred$upper[,2], col = "red", lty = "dashed")
legend(1,60, legend = c("Actual", "Predicted"), lwd = 2, col = c("black", "red"))
```


Based on the above graph, our forecast was reasonably close for 5/7 predictions (the first four and the last one). It can be observed that our simulation predicted more of a smooth curve compared to the real data which is much more variable. This makes sense because the real data is messy, and our model may not be equipped to replicate this without overfitting. 


# Part 2: Simulating Univariate Time Series Models

We now simulate a year of synthetic observations of daily maximum nitrogen dioxide (NO2) concentrations from your selected model. The seed is set to 1 so that the same results can be obtained each time. You will need to consider the sum of the linear models of the trend + seasonality, and the residual models. Assess and compare the model’s performance with respect to:

#### 2.1 Ability to reproduce the appearance of time series. Plot observations and simulations and visually compare their characteristics.

We are selecting the arima(1,1,1) model derived from automatic selection for this section because it has a lower AIC and BIC than the ar(1) model, with similar diagnostics.

```{r}
# Simulate 50 years of monthly minimum temperatures with the best model
# auto.arima builds ARMA(1,1) model
set.seed(1)
auto.sim <- arima.sim(n=365, list(ar=c(NO2.auto1$coef[1]),
                                      ma=c(NO2.auto1$coef[2])),
                        sd=sqrt(NO2.auto1$sigma2))
```


```{r}
# Add mean predictions and plot simulation of Tmin
next.1yr.time <- c(1:365)
next.1yr <- data.frame(time.NO2 = next.1yr.time)

next.1.yr.predictions <- predict(NO2.trend.seasonal, newdata=next.1yr)

# plot simulated temperatures
predicted_1yrplot <- autoplot(ts(next.1.yr.predictions + auto.sim), 
                              xlab="Time",ylab="Simulated Max NO2 GT")
```


Here, we generate the predictions and simulation for our ARIMA model. In order to determine the viability of the model, we then turn toward visualizing the simulation with the observed data. 


```{r}
observed_plot <- autoplot(ts(dailyNO2),xlab="Time",ylab="Observed Max NO2 GT")
```

```{r}
ggarrange(predicted_1yrplot,observed_plot,nrow=2,ncol=1)
```

After seeing the two plots we generated, we overlay the plots to get a stronger visualization. 

```{r}
dailyAQ_1yr <- head(dailyAQ,365)
ggplot(dailyAQ_1yr, aes(x=Group.1,y=NO2.GT.)) + geom_line() + 
  geom_line(aes(Group.1, next.1.yr.predictions + auto.sim, color='red'))
```

The visualization above shows the simulated data in red, and the observed data in black. We can see that the simulated data seems to match the observed data within a reasonable deviation.


#### 2.2 Ability to reproduce observed trends. You can assess this by building a linear model of the trend + seasonality of the simulations and comparing the coefficient estimates with the linear model of the trend + seasonality of the observations. What is the percent difference in the coefficient on time?

```{r}
summary(NO2.trend.seasonal)
```


```{r}
# Model seasonality
dailyNO2.ts.sim <- ts(next.1.yr.predictions + auto.sim)

NO2.trend.seasonal.sim <- lm(dailyNO2.ts.sim ~ next.1yr.time + 
                               sin(2*pi*next.1yr.time/7) + cos(2*pi*next.1.yr.predictions/7))

summary(NO2.trend.seasonal.sim)
```


```{r}
# percent difference
((0.2578 - 0.25511) / ((0.2578+0.25511)/2))*100
```


Percent difference for coefficient on time: 1.05%

In order to prove that the observed trends can be reproduced, we compared a simulated linear model of trend + seasonality with the observed linear model of trend + seasonality. For both models, the objective is to compare the coefficients on time and minimize the percent difference between them. The coefficient on time for the simulated model is 0.25511, and the coefficient on time for the observed model is 0.2578. There is a percent difference of 1.05%. With the objective of this exercise to minimize the percent difference, this is an acceptable model and proves that the observed trends can be reproduced accurately 


#### 2.3 Ability to reproduce seasonality of the time series. Analysis can be visual, simply comparing the periodogram of the observations and simulations.



```{r}
# original
pg.NO2<- spec.pgram(dailyNO2.ts,spans=9,demean=T,log='no')
```



```{r}
pg.NO2.sim<- spec.pgram(dailyNO2.ts.sim,spans=9,demean=T,log='no')
```


The periodograms of the original and simulated data match up reasonably well, with the most prominent peak of the simulated data matching with the second highest peak in the original data, representing a weekly seasonality. 


```{r}
# Find the peak, max.omega.NO2
max.omega.NO2<-pg.NO2$freq[which(pg.NO2$spec==max(pg.NO2$spec))]
sim.max.omega.NO2<-pg.NO2.sim$freq[which(pg.NO2.sim$spec==max(pg.NO2.sim$spec))]

# Where is the peak?
max.omega.NO2
sim.max.omega.NO2

# What is the period?
1/max.omega.NO2
1/sim.max.omega.NO2
```


```{r}
# compare first 20 periods of real and simulated data to see how they match up

# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2.sim$spec, decreasing=T, index.return=T)
names(sorted.spec)

# corresponding periods (omegas = frequencies, Ts = periods)
sorted.omegas <- pg.NO2.sim$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2.sim$freq[sorted.spec$ix]

# look at first 20
#sorted.omegas[1:20]
sorted.Ts[1:20]

# the Ts should roughly mimic those of the original data (period)
```


```{r}
# original data 

sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
sorted.Ts.og <- 1/pg.NO2$freq[sorted.spec$ix]

sorted.Ts.og[1:20]
```


Again, the second highest peak of the original data (corresponding to weekly seasonality) mimics the highest peak of the simulated data. This is what we would expect since the model was built under a 7 day period. We conclude that our model is able to reproduce the seasonality within a reasonable degree of variance.


#### 2.4 Ability to reproduce observed mean and variance of the time series (Hint: Use the functions ‘mean(ts)’ and ‘var(ts)’ where ts is a time series, and find the percent difference between observations and simulations)

```{r}
mean(dailyNO2.ts)
mean(dailyNO2.ts.sim)

# % difference
(abs((mean(dailyNO2.ts.sim) - mean(dailyNO2.ts)))/ ((mean(dailyNO2.ts.sim)+mean(dailyNO2.ts))/2))*100
```


```{r}
var(dailyNO2.ts)
var(dailyNO2.ts.sim)

# % difference
(abs((var(dailyNO2.ts.sim) - var(dailyNO2.ts)))/
    ((var(dailyNO2.ts.sim)+var(dailyNO2.ts))/2))*100
```


As seen above, the mean of the simulated time series was only 1.4% different than the mean of the observed time series. The variance has a 15.9% difference. This makes sense because the observed data has a higher degree of variability in comparison to our simulation. 


#### 2.5 Ability to reproduce the autocorrelation of the time series. Analysis can be visual, simply comparing the ACF and PACF of the observations and simulations

```{r}
# compare ACF of observed and simulated time series
e.ts.NO2.1 <- ts(NO2.trend.seasonal$residuals)
e.ts.NO2.sim <- ts(NO2.trend.seasonal.sim$residuals)

NO2.acf1 <- ggAcf(e.ts.NO2.1)
NO2.acf.sim <- ggAcf(e.ts.NO2.sim)

ggarrange(NO2.acf1,NO2.acf.sim,nrow=2,ncol=1)
```

As seen in the ACF’s above, despite not matching up perfectly, both the original data and simulated data exhibit sinusoidal decay. Therefore, we believe the simulated model is an acceptable representation of the observed model. Based on their respective ACF’s, the autocorrelation of the time series can be reproduced. 


```{r}

NO2.pacf1 <- ggPacf(e.ts.NO2.1)
NO2.pacf.sim <- ggPacf(e.ts.NO2.sim)

ggarrange(NO2.pacf1,NO2.pacf.sim,nrow=2,ncol=1)

```

Again, although the PACFs of the observed and simulated data do not match up perfectly, they both exhibit sinusoidal decay. This shows that the moving average component, as selected through our automatic model selection, is being represented in both. 


Though our model could be improved, we believe that overall our simulated data adequately reproduced the appearance of the time series, observed trends, seasonality, observed mean and variance, and autocorrelation of the time series. Since we are working with real and imperfect data, we acknowledge that our model and diagnostics may not be ideal. However, we maintain that our model is within a reasonable bound of accuracy and predictive ability.

