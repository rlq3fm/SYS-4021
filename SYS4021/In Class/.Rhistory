sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
pg.NO2 <- spec.pgram(dailyNO2.ts,spans=9,demean=T,log='no')
# What are the periods of the next biggest peaks?
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
names(sorted.spec)
# corresponding periods (omegas = frequences, Ts = periods)
sorted.omegas <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
pg.NO2 <- spec.pgram(dailyNO2.ts)
# What are the periods of the next biggest peaks?
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
names(sorted.spec)
# corresponding periods (omegas = frequencies, Ts = periods)
sorted.omegas <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
# What are the periods of the next biggest peaks?
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
names(sorted.spec)
# corresponding periods (omegas = frequencies, Ts = periods)
sorted.omegas <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
#*****************************
#
# Load the data & source files
#
#*****************************
datadir <- "C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/In Class/Data"
sourcedir <- "C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/In Class"
##Load the Virginia weather data
setwd(datadir)
VAweather <- read.table('VirginiaWeatherData.csv',header=T,sep=',')
setwd(sourcedir)
# Create time series of monthly Richmond precipitation and minimum temperature
Richmond.P <- VAweather$R_Precip
Richmond.Tmin <- VAweather$R_Tmin
##Use the ts() command to get a time series of Richmond.P
precip.ts<-ts(Richmond.P)
##Use the ts() command to get a time series of Richmond.Tmin
temp.ts<-ts(Richmond.Tmin)
##Load libraries (install if necessary)
library(forecast)
library(ggplot2)
library(mtsdi)
library(tidyverse)
library(lubridate)
library("car")
library(ggfortify)
library(ggpubr)
library(tseries)
date <- VAweather %>% select(Year, Month) %>% mutate(date = make_datetime(Year,Month))
VAweather$date <- date$date
# Replace -999s with NA, remove last 7 rows, and re-make time series
VAweather[VAweather == -999.0] <- NA
VAweather <- VAweather[1:(dim(VAweather)[1]-7),]
Richmond.P <- VAweather$R_Precip
Richmond.Tmin <- VAweather$R_Tmin
precip.ts<-ts(Richmond.P)
temp.ts<-ts(Richmond.Tmin)
# Impute missing values
f <- ~ C_Precip + C_Tmax + C_Tmin + R_Precip + R_Tmax + R_Tmin
t <- c(seq(1,dim(VAweather)[1]))
# Replace VAweather with imputed data
VAweather[,3:8] <- imputedData$filled.dataset
imputedData <- mnimput(f, VAweather[,3:8], eps=1e-3, ts=TRUE, method="gam",
ga.control=list(formula=paste(names(VAweather[,3:8]),'~ns(t,6)')))
# Replace VAweather with imputed data
VAweather[,3:8] <- imputedData$filled.dataset
Richmond.P <- VAweather$R_Precip
Richmond.Tmin <- VAweather$R_Tmin
precip.ts<-ts(Richmond.P)
temp.ts<-ts(Richmond.Tmin)
# Get the periodogram for precip.ts
pg.precip <- spec.pgram(precip.ts,spans=9,demean=T,log='no')
spec.precip <- data.frame(freq=pg.precip$freq, spec=pg.precip$spec)
# What are the periods of the next biggest peaks?
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.precip$spec, decreasing=T, index.return=T)
names(sorted.spec)
# corresponding periods (omegas = frequences, Ts = periods)
sorted.omegas <- pg.precip$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.precip$freq[sorted.spec$ix]
# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
pg.NO2 <- spec.pgram(dailyNO2.ts,spans=9,demean=T,log='no')
require("knitr")
datadir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/In Class/Data/AirQualityUCI"
sourcedir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/Project 2"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
library(ggplot2)
library(ggfortify)
library(tseries)
library(ggpubr)
library(tidyverse)
setwd(datadir)
airquality = read.csv('AirQualityUCI.csv')
# replace -200 with NA
airquality[airquality == -200] <- NA
# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}
setwd(sourcedir)
# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]
# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam',
ga.control=list(formula=paste(names(AQdata)[c(1:2)],'~ns(t,2)')))
# set airquality to imputed data
AQdata <- i$filled.dataset
# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
# use dataframe dailyAQ
dailyNO2 <- dailyAQ$NO2.GT.
dailyNO2.ts <- ts(dailyNO2)
# remove last 7 days
dailyNO2.ts <- (dailyNO2.ts[1:(length(dailyNO2.ts)-7)])
# create time element
time.NO2<-c(1:(length(dailyNO2.ts)))
pg.NO2 <- spec.pgram(dailyNO2.ts,spans=9,demean=T,log='no')
# Find the peak, max.omega.NO2
max.omega.NO2<-pg.NO2$freq[which(pg.NO2$spec==max(pg.NO2$spec))]
# Where is the peak?
max.omega.NO2
# What is the period?
1/max.omega.NO2
# What are the periods of the next biggest peaks?
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
names(sorted.spec)
# corresponding periods (omegas = frequencies, Ts = periods)
sorted.omegas <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
# What are the periods of the next biggest peaks?
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
names(sorted.spec)
# corresponding periods (omegas = frequencies, Ts = periods)
sorted.omegas <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
require("knitr")
datadir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/In Class/Data/AirQualityUCI"
sourcedir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/Project 2"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
library(ggplot2)
library(ggfortify)
library(tseries)
library(ggpubr)
library(tidyverse)
setwd(datadir)
airquality = read.csv('AirQualityUCI.csv')
# replace -200 with NA
airquality[airquality == -200] <- NA
# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}
setwd(sourcedir)
# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]
# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam',
ga.control=list(formula=paste(names(AQdata)[c(1:2)],'~ns(t,2)')))
# set airquality to imputed data
AQdata <- i$filled.dataset
# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
# use dataframe dailyAQ
dailyNO2 <- head(dailyAQ$NO2.GT., -7)
dailyNO2.ts <- ts(dailyNO2)
# create time element
time.NO2<-c(1:(length(dailyNO2.ts)))
pg.NO2 <- spec.pgram(dailyNO2.ts,spans=9,demean=T,log='no')
# Find the peak, max.omega.NO2
max.omega.NO2<-pg.NO2$freq[which(pg.NO2$spec==max(pg.NO2$spec))]
# Where is the peak?
max.omega.NO2
# What is the period?
1/max.omega.NO2
# What are the periods of the next biggest peaks?
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
names(sorted.spec)
# corresponding periods (omegas = frequencies, Ts = periods)
sorted.omegas <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
sorted.spec
require("knitr")
datadir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/In Class/Data/AirQualityUCI"
sourcedir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/Project 2"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
library(ggplot2)
library(ggfortify)
library(tseries)
library(ggpubr)
library(tidyverse)
setwd(datadir)
airquality = read.csv('AirQualityUCI.csv')
# replace -200 with NA
airquality[airquality == -200] <- NA
# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}
setwd(sourcedir)
# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]
# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam',
ga.control=list(formula=paste(names(AQdata)[c(1:2)],'~ns(t,2)')))
# set airquality to imputed data
AQdata <- i$filled.dataset
# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
# use dataframe dailyAQ
dailyNO2 <- dailyAQ$NO2.GT.
dailyNO2.ts <- ts(dailyNO2)
# remove last 7 days
dailyNO2.ts1 <- (dailyNO2.ts[1:(length(dailyNO2.ts)-7)])
# create time element
time.NO2<-c(1:(length(dailyNO2.ts)))
pg.NO2 <- spec.pgram(dailyNO2.ts,spans=9,demean=T,log='no')
# Find the peak, max.omega.NO2
max.omega.NO2<-pg.NO2$freq[which(pg.NO2$spec==max(pg.NO2$spec))]
# Where is the peak?
max.omega.NO2
# What is the period?
1/max.omega.NO2
# What are the periods of the next biggest peaks?
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
names(sorted.spec)
# corresponding periods (omegas = frequencies, Ts = periods)
sorted.omegas <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
require("knitr")
datadir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/In Class/Data/AirQualityUCI"
sourcedir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/Project 2"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
library(ggplot2)
library(ggfortify)
library(tseries)
library(ggpubr)
library(tidyverse)
setwd(datadir)
airquality = read.csv('AirQualityUCI.csv')
# replace -200 with NA
airquality[airquality == -200] <- NA
# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}
setwd(sourcedir)
# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]
# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam',
ga.control=list(formula=paste(names(AQdata)[c(1:2)],'~ns(t,2)')))
# set airquality to imputed data
AQdata <- i$filled.dataset
# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
# use dataframe dailyAQ, remove last 7 days
dailyNO2 <- head(dailyAQ$NO2.GT., -7)
dailyNO2.ts <- ts(dailyNO2)
# create time element
time.NO2<-c(1:(length(dailyNO2.ts)))
pg.NO2 <- spec.pgram(dailyNO2.ts,spans=9,demean=T,log='no')
# Find the peak, max.omega.NO2
max.omega.NO2<-pg.NO2$freq[which(pg.NO2$spec==max(pg.NO2$spec))]
# Where is the peak?
max.omega.NO2
# What is the period?
1/max.omega.NO2
# What are the periods of the next biggest peaks?
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
names(sorted.spec)
# corresponding periods (omegas = frequencies, Ts = periods)
sorted.omegas <- pg.NO2$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2$freq[sorted.spec$ix]
# look at first 20
sorted.omegas[1:20]
sorted.Ts[1:20]
# Model seasonality
# from before: period = 7
NO2.trend.seasonal <- lm(dailyNO2.ts ~ time.NO2 + sin(2*pi*time.NO2/7)
+ cos(2*pi*time.NO2/7))
summary(NO2.trend.seasonal)
dailyAQ1 <- head(dailyAQ, -7)
# Plot seasonal model
ggplot(dailyAQ1, aes(x=Group.1,y=NO2.GT.)) + geom_line() +
geom_line(aes(x=Group.1,y=NO2.trend.seasonal$fitted.values),color="red") +
xlab("") + ylab("GT NO2")
# Model diagnostics for NO2.trend.seasonal
autoplot(NO2.trend.seasonal, labels.id = NULL)
# check to make sure no points have cooks distance higher than 0.5
autoplot(NO2.trend.seasonal,which=4,ncol=1,label.size=3) + theme_bw()
plot(dailyNO2.ts)
NO2.trend<-lm(dailyNO2.ts ~ time.NO2)
summary(NO2.trend)
# Plot NO2.trend model
ggplot(dailyAQ, aes(x=Group.1,y=NO2.GT.)) + geom_line() +
stat_smooth(method="lm",col="red") + xlab("") + ylab("GT NO2")
# Model diagnostics for temp.trend
autoplot(NO2.trend, labels.id = NULL)
# check to make sure no points have cooks distance higher than 0.05
autoplot(NO2.trend,which=4,ncol=1,label.size=3) + theme_bw()
# using acf and pcf
# Get the residuals from the NO2.trend model above and store in e.ts.NO2:
e.ts.NO2 <- ts(NO2.trend$residuals)
# Plot the residuals for the temp.trend model
autoplot(e.ts.NO2)
# ACF
NO2.acf <- ggAcf(e.ts.NO2)
# PACF
NO2.pacf <- ggPacf(e.ts.NO2)
# Plot acf and pacf side by side for easier examination
ggarrange(NO2.acf,NO2.pacf,nrow=2,ncol=1)
# build ar1 model
NO2.ar1 <- arma(e.ts.NO2, order=c(1,0))
summary(NO2.ar1)
# without intercept
NO2.ar1 <- arma(e.ts.NO2, order=c(1,0), include.intercept = FALSE)
summary(NO2.ar1)
# using arima
# ar(1) p=1
NO2.ar1.1 <- arima(e.ts.NO2, order=c(1,0,0), include.mean=FALSE)
summary(NO2.ar1.1)
# automatic model selection
NO2.auto <- auto.arima(e.ts.NO2)
summary(NO2.auto)
NO2.auto1 <- auto.arima(e.ts.NO2,approximation=FALSE)
summary(NO2.auto1) # smaller AIC - use this
# AIC:
AIC(NO2.ar1.1)
AIC(NO2.auto1)
# BIC
BIC(NO2.ar1.1)
BIC(NO2.auto1)
# diagnostics: residuals v. fit
model1 = ggplot() + geom_point(aes(x=fitted(NO2.ar1.1), y=NO2.ar1.1$residuals)) + ggtitle("AR1")
model2 = ggplot() + geom_point(aes(x=fitted(NO2.auto1), y=NO2.auto1$residuals)) + ggtitle("Auto")
ggarrange(model1, model2, ncol=2, nrow=1)
# assess normality of residuals
model1 = qplot(sample=NO2.ar1.1$residuals) + stat_qq_line(color="red") + ggtitle("AR1")
model2 = qplot(sample=NO2.auto1$residuals) + stat_qq_line(color="red") + ggtitle("Auto")
ggarrange(model1, model2, ncol=2, nrow=1)
ggtsdiag(NO2.ar1.1,gof.lag=20)
ggtsdiag(NO2.auto1,gof.lag=20)
NO2.auto.forecast <- forecast(NO2.auto1, h=7)
autoplot(NO2.auto.forecast,main="Forecasts from ARIMA(1,1,1) with zero mean")
anova(NO2.trend,NO2.trend.seasonal)
AIC(NO2.trend)
AIC(NO2.trend.seasonal)
# Prediction performance
# Create test set from temp data set with last 7 days
# The test period in days
next.7d.time <- c((length(dailyNO2)-6):(length(dailyNO2)))
# The test data frame
next.7d <- data.frame(time.NO2 = next.7d.time, NO2 = dailyNO2[next.7d.time])
# The actual time series for the test period
next.7d.ts <- ts(next.7d$NO2)
# Prediction for the next 6 months by temp.auto:
E_Y.pred <- predict(NO2.trend.seasonal, newdata=next.7d)
e_t.pred <- forecast(NO2.auto1, h=7)
next.7d.prediction <- E_Y.pred + e_t.pred$mean
# MSE:
mean((next.7d.prediction-next.7d$NO2)^2)
# Plot actual values and predicted values
plot(ts(next.7d$NO2),type='o',ylim=c(150,210))
lines(ts(next.7d.prediction),col='red',type='o')
lines(1:7, E_Y.pred + e_t.pred$lower[,2], col = "red", lty = "dashed")
lines(1:7, E_Y.pred + e_t.pred$upper[,2], col = "red", lty = "dashed")
legend(1,60, legend = c("Actual", "Predicted"), lwd = 2, col = c("black", "red"))
# Plot actual values and predicted values
plot(ts(next.7d$NO2),type='o',ylim=c(120,230))
lines(ts(next.7d.prediction),col='red',type='o')
lines(1:7, E_Y.pred + e_t.pred$lower[,2], col = "red", lty = "dashed")
lines(1:7, E_Y.pred + e_t.pred$upper[,2], col = "red", lty = "dashed")
legend(1,60, legend = c("Actual", "Predicted"), lwd = 2, col = c("black", "red"))
# Simulate 50 years of monthly minimum temperatures with the best model
# auto.arima builds ARMA(1,1) model
set.seed(1)
auto.sim <- arima.sim(n=365, list(ar=c(NO2.auto1$coef[1]),
ma=c(NO2.auto1$coef[2])),
sd=sqrt(NO2.auto1$sigma2))
# Add mean predictions and plot simulation of Tmin
next.1yr.time <- c(1:365)
next.1yr <- data.frame(time.NO2 = next.1yr.time)
next.1.yr.predictions <- predict(NO2.trend.seasonal, newdata=next.1yr)
# plot simulated temperatures
predicted_1yrplot <- autoplot(ts(next.1.yr.predictions + auto.sim),
xlab="Time",ylab="Simulated Max NO2 GT")
# Add mean predictions and plot simulation of Tmin
next.1yr.time <- c(1:365)
next.1yr <- data.frame(time.NO2 = next.1yr.time)
next.1.yr.predictions <- predict(NO2.trend.seasonal, newdata=next.1yr)
# plot simulated temperatures
predicted_1yrplot <- autoplot(ts(next.1.yr.predictions + auto.sim),
xlab="Time",ylab="Simulated Max NO2 GT")
observed_plot <- autoplot(ts(dailyNO2),xlab="Time",ylab="Observed Max NO2 GT")
ggarrange(predicted_1yrplot,observed_plot,nrow=2,ncol=1)
dailyAQ_1yr <- head(dailyAQ,365)
ggplot(dailyAQ_1yr, aes(x=Group.1,y=NO2.GT.)) + geom_line() +
geom_line(aes(Group.1, next.1.yr.predictions + auto.sim, color='red'))
summary(NO2.trend.seasonal)
# Model seasonality
dailyNO2.ts.sim <- ts(next.1.yr.predictions + auto.sim)
NO2.trend.seasonal.sim <- lm(dailyNO2.ts.sim ~ next.1yr.time +
sin(2*pi*next.1yr.time/7) + cos(2*pi*next.1.yr.predictions/7))
summary(NO2.trend.seasonal.sim)
# percent difference
((0.2578 - 0.25511) / ((0.2578+0.25511)/2))*100
# percent difference
((0.2578 - 0.25511) / ((0.2578+0.25511)/2))*100
# original
pg.NO2<- spec.pgram(dailyNO2.ts,spans=9,demean=T,log='no')
pg.NO2.sim<- spec.pgram(dailyNO2.ts.sim,spans=9,demean=T,log='no')
# Find the peak, max.omega.NO2
max.omega.NO2<-pg.NO2$freq[which(pg.NO2$spec==max(pg.NO2$spec))]
sim.max.omega.NO2<-pg.NO2.sim$freq[which(pg.NO2.sim$spec==max(pg.NO2.sim$spec))]
# Where is the peak?
max.omega.NO2
sim.max.omega.NO2
# What is the period?
1/max.omega.NO2
1/sim.max.omega.NO2
# compare first 20 periods of real and simulated data to see how they match up
# sort spectrum from largest to smallest and find index
sorted.spec <- sort(pg.NO2.sim$spec, decreasing=T, index.return=T)
names(sorted.spec)
# corresponding periods (omegas = frequencies, Ts = periods)
sorted.omegas <- pg.NO2.sim$freq[sorted.spec$ix]
sorted.Ts <- 1/pg.NO2.sim$freq[sorted.spec$ix]
# look at first 20
#sorted.omegas[1:20]
sorted.Ts[1:20]
# the Ts should roughly mimic those of the original data (period)
# original data
sorted.spec <- sort(pg.NO2$spec, decreasing=T, index.return=T)
sorted.Ts.og <- 1/pg.NO2$freq[sorted.spec$ix]
sorted.Ts.og[1:20]
mean(dailyNO2.ts)
mean(dailyNO2.ts.sim)
# % difference
(abs((mean(dailyNO2.ts.sim) - mean(dailyNO2.ts)))/ ((mean(dailyNO2.ts.sim)+mean(dailyNO2.ts))/2))*100
var(dailyNO2.ts)
var(dailyNO2.ts.sim)
# % difference
(abs((var(dailyNO2.ts.sim) - var(dailyNO2.ts)))/
((var(dailyNO2.ts.sim)+var(dailyNO2.ts))/2))*100
# compare ACF of observed and simulated time series
e.ts.NO2.1 <- ts(NO2.trend.seasonal$residuals)
e.ts.NO2.sim <- ts(NO2.trend.seasonal.sim$residuals)
NO2.acf1 <- ggAcf(e.ts.NO2.1)
NO2.acf.sim <- ggAcf(e.ts.NO2.sim)
ggarrange(NO2.acf1,NO2.acf.sim,nrow=2,ncol=1)
NO2.pacf1 <- ggPacf(e.ts.NO2.1)
NO2.pacf.sim <- ggPacf(e.ts.NO2.sim)
ggarrange(NO2.pacf1,NO2.pacf.sim,nrow=2,ncol=1)
