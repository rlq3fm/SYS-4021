# Installs pacman ("package manager") if needed
install.packages("pacman")
getwd()
# PACKAGES ############################################
install.packages("psych")
library(psych)
library(pacman)
?p_help
getwd()
#Windows
setwd("C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/Data")
# READ IN A SINGLE DATA FILE ###########################################
iriscsv <- read.csv("iris.txt")
library(datasets)  # Load built-in datasets
head(iris)         # Show the first six lines of iris data
summary(iris)      # Summary statistics for iris data
plot(iris)         # Scatterplot matrix for iris data
source("~/SYS4021/In Class/IntroR.R", echo=TRUE)
describe(iris$Sepal.Length)  # One quantitative variable
library(datasets)  # Load built-in datasets
head(iris)         # Show the first six lines of iris data
summary(iris)      # Summary statistics for iris data
plot(iris)         # Scatterplot matrix for iris data
describe(iris)               # Entire data frame
# Clear environment
rm(list = ls())
getwd()
# Read in the accident files one at at time
# for the first questions in the in-class assignment we will
# only use data from 2020
accident_data_20 <- read.csv("RailAccidents20.csv")
getwd()
setwd("C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/Data")
getwd()
# Read in the accident files one at at time
# for the first questions in the in-class assignment we will
# only use data from 2020
accident_data_20 <- read.csv("RailAccidents20.csv")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(psych)
library(ggplot2)
library(GGally)
library(devtools)
library(ggfortify)
library(here)
library(dplyr)
library(ggpubr)
library(MASS)
library(lindia)
setwd("C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/")
# read in data
housing <- read.csv("housing.csv")
ggplot(data=housing, aes(x=price)) + geom_boxplot()
# no outliers
summary(housing$price)
boxplot.stats(housing$price)
# upper whisker is max, so 1250000
pairs.panels(housing[,c("sqft", "City", "bedrooms", "baths", "price")])
# strongest correlation is 0.65
# price and sqft
# Y = B0 + B1X1 + B2X2 + B3X3
# X1 = sqft
# X2 = bedrooms
# X3 = baths
house.main<-lm(price~sqft+bedrooms+baths, data=housing)
summary(house.main)
coef(house.main)
# B sqft = 221.378 -> $221.378 change in price
house.inter<-lm(price~(sqft+bedrooms+baths)^2, data=housing)
summary(house.inter)
anova(house.main,house.inter)
# house.main adjusted-R2:
summary(house.main)$adj.r.squared
# house.inter adjusted-R2:
summary(house.inter)$adj.r.squared
# house.main AIC:
AIC(house.main)
# house.inter AIC:
AIC(house.inter)
autoplot(house.main, which=4, ncol = 1, label.size = 3) + theme_bw()
cooks <- cooks.distance(house.main)
cooks[(cooks > 0.5)] # no points > 0.5
install.packages("olsrr")
library(olsrr)
library(olsrr)
ols_test_breusch_pagan(house.main)
par(mfrow = c(2, 2))
plot(house.main)
autoplot(house.main, which=1, ncol = 1, label.size = 3) + theme_bw()
boxcox(house.main)
boxcox(house.main, plotit = F)$x[which.max(boxcox(house.main, plotit = F)$y)]
require("knitr")
datadir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/In Class/Data/AirQualityUCI"
sourcedir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/Project 2"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
setwd(datadir)
airquality = read.csv('AirQualityUCI.csv')
# replace -200 with NA
airquality[airquality == -200] <- NA
# convert integer type to numeric
intcols = c(4,5,7,8,9,10,11,12)
for(i in 1:length(intcols)){
airquality[,intcols[i]] <- as.numeric(airquality[,intcols[i]])
}
setwd(sourcedir)
# create new data frame with just CO and NO2
AQdata = airquality[,c(3,10)]
# impute missing air quality data
f <- ~ CO.GT. + NO2.GT.
t <- c(seq(1,dim(AQdata)[1],1))
i <- mnimput(f, AQdata, eps=1e-3, ts=TRUE, method='gam', ga.control=list(formula=paste(names(AQdata)[c(1:2)],'~ns(t,2)')))
# set airquality to imputed data
AQdata <- i$filled.dataset
# aggregate to daily maxima for model building
dailyAQ <- aggregate(AQdata, by=list(as.Date(airquality[,1],"%m/%d/%Y")), FUN=max)
View(dailyAQ)
# use dataframe dailyAQ
dailyNO2 <- dailyAQ$NO2.GT.
dailyNO2.ts <- ts(dailyNO2)
# remove last 7 days
dailyNO2.ts <- (dailyNO2.ts[1:(length(spam.ts)-7)])
# remove last 7 days
dailyNO2.ts <- (dailyNO2.ts[1:(length(dailyNO2.ts)-7)])
# create time element
time.NO2<-c(1:(length(dailyNO2.ts)))
autoplot(dailyNO2.ts,ylab="NO2",xlab="Day")
plot(dailyNO2.ts)
pg.NO2 <- spec.pgram(dailyNO2.ts,spans=9,demean=T,log='no')
# Find the peak, max.omega.NO2
max.omega.NO2<-pg.NO2$freq[which(pg.NO2$spec==max(pg.NO2$spec))]
# Where is the peak?
max.omega.NO2
# What is the period?
1/max.omega.NO2
plot(dailyNO2.ts)
NO2.trend<-lm(temp.ts ~ time.NO2)
NO2.trend<-lm(dailyNO2.ts ~ time.NO2)
summary(NO2.trend)
# Plot temp.trend model
ggplot(dailyAQ, aes(x=Group.1,y=NO2.GT.)) + geom_line() +
stat_smooth(method="lm",col="red") + xlab("") + ylab("GT NO2")
library(ggplot2)
# Plot temp.trend model
ggplot(dailyAQ, aes(x=Group.1,y=NO2.GT.)) + geom_line() +
stat_smooth(method="lm",col="red") + xlab("") + ylab("GT NO2")
# Model diagnostics for temp.trend
autoplot(NO2.trend, labels.id = NULL)
library(ggfortify)
# Model diagnostics for temp.trend
autoplot(NO2.trend, labels.id = NULL)
# Model seasonality
NO2.trend.seasonal <- lm(dailyNO2.ts ~ time.NO2 + sin(2*pi*time.NO2/12) + cos(2*pi*time.NO2/12))
summary(NO2.trend.seasonal)
# Plot seasonal model
ggplot(dailyAQ, aes(x=Group.1,y=NO2.GT.)) + geom_line() +
geom_line(aes(x=Group.1,y=NO2.trend.seasonal$fitted.values),color="red") +
xlab("") + ylab("GT NO2")
View(NO2.trend.seasonal)
# use dataframe dailyAQ
dailyNO2 <- dailyAQ$NO2.GT.
dailyNO2.ts <- ts(dailyNO2)
# remove last 7 days
dailyNO2.ts <- (dailyNO2.ts[1:(length(dailyNO2.ts)-7)])
# create time element
time.NO2<-c(1:(length(dailyNO2.ts)))
# Model seasonality
NO2.trend.seasonal <- lm(dailyNO2.ts ~ time.NO2 + sin(2*pi*time.NO2/12) + cos(2*pi*time.NO2/12))
summary(NO2.trend.seasonal)
View(NO2.trend.seasonal)
dailyAQ1 <- head(dailyAQ, -7)
# Plot seasonal model
ggplot(dailyAQ1, aes(x=Group.1,y=NO2.GT.)) + geom_line() +
geom_line(aes(x=Group.1,y=NO2.trend.seasonal$fitted.values),color="red") +
xlab("") + ylab("GT NO2")
# Model diagnostics for NO2.trend.seasonal
autoplot(NO2.trend.seasonal, labels.id = NULL)
# Plot temp.trend model
ggplot(dailyAQ, aes(x=Group.1,y=NO2.GT.)) + geom_line() +
stat_smooth(method="lm",col="red") + xlab("") + ylab("GT NO2")
# Model diagnostics for temp.trend
autoplot(NO2.trend, labels.id = NULL)
# using acf and pcf
# Get the residuals from the NO2.trend model above and store in e.ts.NO2:
e.ts.NO2 <- ts(NO2.trend$residuals)
# Plot the residuals for the temp.trend model
autoplot(e.ts.NO2)
# ACF
NO2.acf <- ggAcf(e.ts.NO2)
# PACF
NO2.pacf <- ggPacf(e.ts.NO2)
# Plot acf and pacf side by side for easier examination
ggarrange(NO2.acf,NO2.pacf,nrow=2,ncol=1)
library(ggpubr)
# Plot acf and pacf side by side for easier examination
ggarrange(NO2.acf,NO2.pacf,nrow=2,ncol=1)
# build ar1 model
NO2.ar1 <- arma(e.ts.NO2, order=c(1,0))
library(tseries)
# build ar1 model
NO2.ar1 <- arma(e.ts.NO2, order=c(1,0))
summary(NO2.ar1)
# without intercept
NO2.ar1 <- arma(e.ts.NO2, order=c(1,0), include.intercept = FALSE)
summary(NO2.ar1)
# automatic model selection
NO2.auto <- auto.arima(e.ts.NO2)
summary(NO2.auto)
NO2.auto1 <- auto.arima(e.ts.NO2,approximation=FALSE)
summary(temp.auto1)
summary(NO2.auto1)
# automatic model selection
NO2.auto <- auto.arima(e.ts.NO2)
summary(NO2.auto)
NO2.auto1 <- auto.arima(e.ts.NO2,approximation=FALSE)
summary(NO2.auto1)
# AIC:
AIC(NO2.ar1)
# BIC
BIC(NO2.ar1)
require("knitr")
datadir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/In Class/Data/AirQualityUCI"
sourcedir <-"C:/Users/Student/OneDrive - University of Virginia/Documents/SYS4021/Project 2"
opts_knit$set(root.dir = sourcedir)
library(forecast)
library(mtsdi)
library(MTS)
library(ggplot2)
library(ggfortify)
library(tseries)
library(ggpubr)
library(tidyverse)
library()
# ar(1) p=1
NO2.ar1.1 <- arima(e.ts.NO2, order=c(1,0,0), include.mean=FALSE)
summary(NO2.ar1.1)
# AIC:
AIC(NO2.ar1.1)
# AIC:
AIC(NO2.ar1.1)
AIC(NO2.auto1)
# BIC
BIC(NO2.ar1)
# BIC
BIC(NO2.ar1.1)
BIC(NO2.auto1)
# diagnostics
model1 = ggplot() + geom_point(aes(x=fitted(NO2.ar1.1), y=NO2.ar1.1$residuals)) + ggtitle("AR1")
model2 = ggplot() + geom_point(aes(x=fitted(NO2.auto1), y=NO2.auto1$residuals)) + ggtitle("Auto")
ggarrange(model1, model2, ncol=2, nrow=1)
# assess normality of residuals
model1 = qplot(sample=NO2.ar1.1$residuals) + stat_qq_line(color="red") + ggtitle("AR1")
model2 = qplot(sample=NO2.auto1$residuals) + stat_qq_line(color="red") + ggtitle("Auto")
ggarrange(model1, model2, ncol=2, nrow=1)
ggtsdiag(NO2.ar1.1,gof.lag=20)
ggtsdiag(NO2.auto1,gof.lag=20)
NO2.auto.forecast <- forecast(NO2.auto1, h=7)
autoplot(NO2.auto.forecast,main="Forecasts from ARIMA(1,1,1) with zero mean")
# The test period in days
next.7d.time <- c((length(dailyNO2)-7):(length(dailyNO2)))
# The test period in days
next.7d.time <- c((length(dailyNO2)-6):(length(dailyNO2)))
next.7d.time
# The test data frame
next.7d <- data.frame(time.NO2 = next.7d.time, NO2 = dailyNO2[next.7d.time])
# The actual time series for the test period
next.7d.ts <- ts(next.7d$NO2)
# Prediction for the next 6 months by temp.auto:
E_Y.pred <- predict(NO2.trend, newdata=next.7d)
e_t.pred <- forecast(NO2.auto1, h=7)
next.7d.prediction <- E_Y.pred + e_t.pred$mean
# MSE:
mean((next.7d.prediction-next.7d$NO2)^2)
